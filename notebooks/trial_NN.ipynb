{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86191bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/miniconda3/envs/ctpesto/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch as pt\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split\n",
    "from src.dataset import MolDataset\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import f1_score, cohen_kappa_score\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d918ff8d-2292-4c00-99d1-ff89349cc298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format =   'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa80e3ff-ebc5-4b0e-9cde-d5d5fc8f710f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "pt.manual_seed(1158)\n",
    "device = \"cuda\" if pt.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b9847a-bb53-413a-87fa-acf4a0d62d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "078eb211-57a8-4388-b013-d6eac80d4d97",
   "metadata": {},
   "source": [
    "# Dataset and Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76bb410f-d5cc-4a9e-9c38-a0fcd890882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 18000\n",
    "dataset = MolDataset(\"../data/preprocessed/X.pk\", \n",
    "                     y_datafile=\"../data/preprocessed/Y.pk\", normal = True)\n",
    "train_dataset, test_dataset = random_split(dataset, [len(dataset) - N, N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13f91bcf-7d0c-4f99-bab6-7ced39a6233e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52711"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b8377d1-731a-4e1f-9bcb-4fd85ec4ca15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.3105030e-03,  3.1218042e-03,  1.4059457e-01,  6.9875127e-01,\n",
       "        0.0000000e+00,  6.6563778e-02,  3.1595469e-02,  3.5106074e-02,\n",
       "        5.6169719e-02,  0.0000000e+00,  3.8616683e-02,  2.3026923e-02,\n",
       "        2.9138044e-01,  1.4855877e-03,  3.5106074e-03,  1.0531822e-02,\n",
       "        0.0000000e+00,  4.7062942e-01,  3.7212440e-01,  4.2127289e-02,\n",
       "       -1.6148794e-04,  1.8255159e-01,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  3.5106074e-03,  0.0000000e+00,  3.5106074e-03,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[33][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da9686d4-2ee2-4bdc-8e27-e373385dd645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5257127987807144\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset)/np.sum(dataset[:][1], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d169e47c-32c8-40e6-9582-046aa5f66a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "740"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test_dataset[:][1] ==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13a6fe60-e24a-4a48-8f57-0137b22e87cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(66, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "                        nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "                        nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "                        nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "                        nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "                        nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 3),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af828146-b788-417f-a749-e92f98f86804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=66, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (13): ReLU()\n",
      "    (14): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (15): ReLU()\n",
      "    (16): Linear(in_features=64, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2769f48-fa11-4426-a166-3094ea6a2b9c",
   "metadata": {},
   "source": [
    "#  Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42790ed4-2c13-4bd2-bb55-84d07c5e7acf",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db2b0e9-2d4a-4e59-9a21-e99f4a83ee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c98d3a5f-e23d-4933-b96d-c02f7dd4b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [8,2100,11111, 3674,9867]\n",
    "\n",
    "X1 = train_dataset[ids][0]\n",
    "X = pt.tensor(X1, device=device)\n",
    "treu_y = dataset[ids][1]\n",
    "\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "# print(f\"Predicted class: {y_pred}\")\n",
    "# print(f\"True classes: {treu_y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d152511a-613f-4843-b44d-e6f9d8b5fae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3035, 0.3596, 0.3370],\n",
       "        [0.3035, 0.3596, 0.3370],\n",
       "        [0.3035, 0.3596, 0.3370],\n",
       "        [0.3035, 0.3596, 0.3370],\n",
       "        [0.3035, 0.3596, 0.3370]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af2d0b7f-1c24-4d33-b120-02dd7cbba49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 1, 2], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probab.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0a648cb-f691-486b-8aeb-dea44566c6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 2, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treu_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a61abd-6dcf-4a75-a2ab-af9d0bfaebf4",
   "metadata": {},
   "source": [
    "## Parameters of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8adcc18f-bda7-407b-8844-83e648c72d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = nn.BCEWithLogitsLoss(weight=class_weights)\n",
    "class_weights = pt.Tensor([1, 1, 0.05])\n",
    "class_weights.to(device)\n",
    "# weight=class_weights,reduction='mean'\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn.to(device)\n",
    "optimizer = pt.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2120c9-cdf6-413e-8d88-b3ea17a01c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "814d876e-299e-469b-a66b-1bff6c001c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, ycls,  Y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        x = X.to(device)\n",
    "        pred = model(x) \n",
    "        # p = pt.squeeze(pred, dim=1)\n",
    "        yyy = pt.Tensor(ycls).type(pt.LongTensor).to(device)\n",
    "        loss = loss_fn(pred, yyy)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 25 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            # print(f\"score {score}\")\n",
    "\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    score = 0\n",
    "    with pt.no_grad():\n",
    "        for X, ycls, Y in dataloader:\n",
    "            x = X.to(device)\n",
    "            pred = model(x) \n",
    "            yyy = pt.Tensor(ycls).type(pt.LongTensor).to(device)\n",
    "            # loss = loss_fn(p, yyy)\n",
    "            test_loss += loss_fn(pred, yyy)\n",
    "            \n",
    "                        #convert to classes\n",
    "            pred_probab = nn.Softmax(dim=1)(pred)\n",
    "            pred_cats = np.array(pred_probab.argmax(1).cpu())  \n",
    "            # # score = f1_score(pred_cats, ycls, average=None)\n",
    "            # score = cohen_kappa_score(pred_cats, ycls)\n",
    "            ts = f1_score(pred_cats, ycls, average=None)\n",
    "            ts2 = cohen_kappa_score(pred_cats, ycls)\n",
    "            # # print(ts.shape)\n",
    "            score += ts2\n",
    "\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    #     correct /= size\n",
    "    #     print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    print(f\"Avg loss: {test_loss:>8f} score: {score/52.}\\n\")\n",
    "    return(score/52.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d3926b-93d3-48f4-abc9-1ebf05410ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.088062  [    0/52711]\n",
      "loss: 0.367582  [25600/52711]\n",
      "loss: 0.293686  [51200/52711]\n",
      "Avg loss: 0.318139 score: 0.0\n",
      "\n",
      "1 Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.338364  [    0/52711]\n",
      "loss: 0.268851  [25600/52711]\n",
      "loss: 0.269277  [51200/52711]\n",
      "Avg loss: 0.304904 score: 0.0\n",
      "\n",
      "2 Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.326655  [    0/52711]\n",
      "loss: 0.272389  [25600/52711]\n",
      "loss: 0.285632  [51200/52711]\n",
      "Avg loss: 0.302840 score: 0.0\n",
      "\n",
      "3 Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.288717  [    0/52711]\n",
      "loss: 0.284730  [25600/52711]\n",
      "loss: 0.300795  [51200/52711]\n",
      "Avg loss: 0.302762 score: 0.0\n",
      "\n",
      "4 Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.284776  [    0/52711]\n",
      "loss: 0.319952  [25600/52711]\n",
      "loss: 0.295664  [51200/52711]\n",
      "Avg loss: 0.303807 score: 0.0\n",
      "\n",
      "5 Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.308664  [    0/52711]\n",
      "loss: 0.267728  [25600/52711]\n",
      "loss: 0.277807  [51200/52711]\n",
      "Avg loss: 0.302496 score: 0.0\n",
      "\n",
      "6 Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.308840  [    0/52711]\n"
     ]
    }
   ],
   "source": [
    "epochs = 45\n",
    "# train model\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1024,\n",
    "                              shuffle=True, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1024,\n",
    "                             shuffle=True, pin_memory=True)\n",
    "scores = []\n",
    "for t in range(epochs):\n",
    "    sys.stdout.write(f\"{t} \") \n",
    "    print(f\"Epoch {t + 1}\\n-------------------------------\")\n",
    "    # logger.store_progress(0, is_train=True, epoch=t+1)\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    s = test_loop(test_dataloader, model, loss_fn)\n",
    "    scores.append(s)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5e567c-15de-4000-ba94-79fe332bb33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores)\n",
    "plt.ylim([-0.00001,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b6d29a-1c5f-4dc2-8266-a885655de7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.save(model.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa952a-6031-416c-9ba3-9937d9c43a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pt.no_grad():\n",
    "    for X, Y in train_dataloader:\n",
    "        x = X.to(device)\n",
    "        y = Y[:,None,:].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c45248-4644-4606-b059-01e82d58c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(x)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bfda51-ab1a-4420-968c-0c99734fc0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62629121-deeb-4e1d-8e9c-090f72ca7291",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd741672-05a4-427d-a1fb-d9f46db85fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0:8,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33240f9-bdf4-40b7-9c0c-cbc2381cce7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
